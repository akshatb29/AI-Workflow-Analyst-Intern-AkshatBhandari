import json
import os
import time
from dotenv import load_dotenv
import google.generativeai as genai

load_dotenv()

# --- CONFIGURATION ---
INPUT_FILE = 'cluster_output.json'
OUTPUT_REPORT = 'final_intent_recommendations.md'
MODEL_NAME = "gemini-2.5-flash" 
MIN_CLUSTER_SIZE = 5 

def setup_gemini():
    """Load API key and initialize model."""
    load_dotenv()
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError("GOOGLE_API_KEY not found in .env file")
    
    genai.configure(api_key=api_key)
    return genai.GenerativeModel(MODEL_NAME)

def create_prompt(cluster, intent_map):
    """Constructs the analysis prompt."""
    samples = cluster['representative_samples']
    
    return f"""
    ROLE: You are a Senior Taxonomy Architect for a Conversational AI.
    
    TASK: Analyze the provided 'Cluster Samples' (real user messages) against the 'Current Intent Map'.
    Determine if this cluster represents a MISSING INTENT, a SPLIT, or fits an EXISTING INTENT.

    --- CURRENT INTENT MAP ---
    {intent_map}

    --- CLUSTER SAMPLES (N={cluster['size']}) ---
    {json.dumps(samples, indent=2)}

    --- REQUIRED OUTPUT FORMAT ---
    ## Proposal: [SPLIT / NEW / EXISTING]
    **Name:** [Proposed Intent Name]
    **Confidence:** [High/Medium/Low]
    **Reasoning:** [Explain WHY based on the samples. Quote specific phrases.]
    """

def generate_report():
    print(f"--- Initializing {MODEL_NAME} ---")
    try:
        model = setup_gemini()
    except Exception as e:
        print(f"Error setting up Gemini: {e}")
        return

    print(f"--- Loading Data from {INPUT_FILE} ---")
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)

    clusters = data['clusters']
    intent_map = data['intent_map_reference']
    
    # Filter for significant clusters
    significant_clusters = [c for c in clusters if c['size'] >= MIN_CLUSTER_SIZE]
    print(f"Found {len(significant_clusters)} clusters to analyze (Size >= {MIN_CLUSTER_SIZE}).")

    report_content = [f"# Automated Intent Expansion Report\nGenerated by {MODEL_NAME}\n"]

    for i, cluster in enumerate(significant_clusters):
        print(f"Analyzing Cluster {cluster['cluster_id']} ({i+1}/{len(significant_clusters)})...")
        
        prompt = create_prompt(cluster, intent_map)
        
        try:
            # Generate content
            response = model.generate_content(prompt)
            
            # Format output for the report
            report_content.append(f"\n---\n")
            report_content.append(f"### Cluster ID: {cluster['cluster_id']} (Size: {cluster['size']})")
            report_content.append(f"**Representative Samples:**\n- " + "\n- ".join([s[:100] + "..." for s in cluster['representative_samples'][:2]]))
            report_content.append(f"\n{response.text}")
            
            # Sleep briefly to avoid aggressive rate limiting
            time.sleep(1) 
            
        except Exception as e:
            print(f"Failed to analyze cluster {cluster['cluster_id']}: {e}")
            report_content.append(f"\nError analyzing Cluster {cluster['cluster_id']}: {e}")

    # Save to Markdown
    print(f"--- Saving Report to {OUTPUT_REPORT} ---")
    with open(OUTPUT_REPORT, 'w', encoding='utf-8') as f:
        f.write("\n".join(report_content))
    
    print("Done! Open the Markdown file to see your results.")

if __name__ == "__main__":
    generate_report()